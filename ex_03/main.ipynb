{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hồi quy logistic với hiệu chỉnh Ridge và Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dữ liệu bằng thư viện pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('../data/sonar_zip/data/sonar_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   attribute_1   208 non-null    float64\n",
      " 1   attribute_2   208 non-null    float64\n",
      " 2   attribute_3   208 non-null    float64\n",
      " 3   attribute_4   208 non-null    float64\n",
      " 4   attribute_5   208 non-null    float64\n",
      " 5   attribute_6   208 non-null    float64\n",
      " 6   attribute_7   208 non-null    float64\n",
      " 7   attribute_8   208 non-null    float64\n",
      " 8   attribute_9   208 non-null    float64\n",
      " 9   attribute_10  208 non-null    float64\n",
      " 10  attribute_11  208 non-null    float64\n",
      " 11  attribute_12  208 non-null    float64\n",
      " 12  attribute_13  208 non-null    float64\n",
      " 13  attribute_14  208 non-null    float64\n",
      " 14  attribute_15  208 non-null    float64\n",
      " 15  attribute_16  208 non-null    float64\n",
      " 16  attribute_17  208 non-null    float64\n",
      " 17  attribute_18  208 non-null    float64\n",
      " 18  attribute_19  208 non-null    float64\n",
      " 19  attribute_20  208 non-null    float64\n",
      " 20  attribute_21  208 non-null    float64\n",
      " 21  attribute_22  208 non-null    float64\n",
      " 22  attribute_23  208 non-null    float64\n",
      " 23  attribute_24  208 non-null    float64\n",
      " 24  attribute_25  208 non-null    float64\n",
      " 25  attribute_26  208 non-null    float64\n",
      " 26  attribute_27  208 non-null    float64\n",
      " 27  attribute_28  208 non-null    float64\n",
      " 28  attribute_29  208 non-null    float64\n",
      " 29  attribute_30  208 non-null    float64\n",
      " 30  attribute_31  208 non-null    float64\n",
      " 31  attribute_32  208 non-null    float64\n",
      " 32  attribute_33  208 non-null    float64\n",
      " 33  attribute_34  208 non-null    float64\n",
      " 34  attribute_35  208 non-null    float64\n",
      " 35  attribute_36  208 non-null    float64\n",
      " 36  attribute_37  208 non-null    float64\n",
      " 37  attribute_38  208 non-null    float64\n",
      " 38  attribute_39  208 non-null    float64\n",
      " 39  attribute_40  208 non-null    float64\n",
      " 40  attribute_41  208 non-null    float64\n",
      " 41  attribute_42  208 non-null    float64\n",
      " 42  attribute_43  208 non-null    float64\n",
      " 43  attribute_44  208 non-null    float64\n",
      " 44  attribute_45  208 non-null    float64\n",
      " 45  attribute_46  208 non-null    float64\n",
      " 46  attribute_47  208 non-null    float64\n",
      " 47  attribute_48  208 non-null    float64\n",
      " 48  attribute_49  208 non-null    float64\n",
      " 49  attribute_50  208 non-null    float64\n",
      " 50  attribute_51  208 non-null    float64\n",
      " 51  attribute_52  208 non-null    float64\n",
      " 52  attribute_53  208 non-null    float64\n",
      " 53  attribute_54  208 non-null    float64\n",
      " 54  attribute_55  208 non-null    float64\n",
      " 55  attribute_56  208 non-null    float64\n",
      " 56  attribute_57  208 non-null    float64\n",
      " 57  attribute_58  208 non-null    float64\n",
      " 58  attribute_59  208 non-null    float64\n",
      " 59  attribute_60  208 non-null    float64\n",
      " 60  Class         208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>attribute_6</th>\n",
       "      <th>attribute_7</th>\n",
       "      <th>attribute_8</th>\n",
       "      <th>attribute_9</th>\n",
       "      <th>attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>attribute_52</th>\n",
       "      <th>attribute_53</th>\n",
       "      <th>attribute_54</th>\n",
       "      <th>attribute_55</th>\n",
       "      <th>attribute_56</th>\n",
       "      <th>attribute_57</th>\n",
       "      <th>attribute_58</th>\n",
       "      <th>attribute_59</th>\n",
       "      <th>attribute_60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_1  attribute_2  attribute_3  attribute_4  attribute_5   \n",
       "0       0.0200       0.0371       0.0428       0.0207       0.0954  \\\n",
       "1       0.0453       0.0523       0.0843       0.0689       0.1183   \n",
       "2       0.0262       0.0582       0.1099       0.1083       0.0974   \n",
       "3       0.0100       0.0171       0.0623       0.0205       0.0205   \n",
       "4       0.0762       0.0666       0.0481       0.0394       0.0590   \n",
       "\n",
       "   attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...   \n",
       "0       0.0986       0.1539       0.1601       0.3109        0.2111  ...  \\\n",
       "1       0.2583       0.2156       0.3481       0.3337        0.2872  ...   \n",
       "2       0.2280       0.2431       0.3771       0.5598        0.6194  ...   \n",
       "3       0.0368       0.1098       0.1276       0.0598        0.1264  ...   \n",
       "4       0.0649       0.1209       0.2467       0.3564        0.4459  ...   \n",
       "\n",
       "   attribute_52  attribute_53  attribute_54  attribute_55  attribute_56   \n",
       "0        0.0027        0.0065        0.0159        0.0072        0.0167  \\\n",
       "1        0.0084        0.0089        0.0048        0.0094        0.0191   \n",
       "2        0.0232        0.0166        0.0095        0.0180        0.0244   \n",
       "3        0.0121        0.0036        0.0150        0.0085        0.0073   \n",
       "4        0.0031        0.0054        0.0105        0.0110        0.0015   \n",
       "\n",
       "   attribute_57  attribute_58  attribute_59  attribute_60  Class  \n",
       "0        0.0180        0.0084        0.0090        0.0032   Rock  \n",
       "1        0.0140        0.0049        0.0052        0.0044   Rock  \n",
       "2        0.0316        0.0164        0.0095        0.0078   Rock  \n",
       "3        0.0050        0.0044        0.0040        0.0117   Rock  \n",
       "4        0.0072        0.0048        0.0107        0.0094   Rock  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>attribute_6</th>\n",
       "      <th>attribute_7</th>\n",
       "      <th>attribute_8</th>\n",
       "      <th>attribute_9</th>\n",
       "      <th>attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>attribute_51</th>\n",
       "      <th>attribute_52</th>\n",
       "      <th>attribute_53</th>\n",
       "      <th>attribute_54</th>\n",
       "      <th>attribute_55</th>\n",
       "      <th>attribute_56</th>\n",
       "      <th>attribute_57</th>\n",
       "      <th>attribute_58</th>\n",
       "      <th>attribute_59</th>\n",
       "      <th>attribute_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       attribute_1  attribute_2  attribute_3  attribute_4  attribute_5   \n",
       "count   208.000000   208.000000   208.000000   208.000000   208.000000  \\\n",
       "mean      0.029164     0.038437     0.043832     0.053892     0.075202   \n",
       "std       0.022991     0.032960     0.038428     0.046528     0.055552   \n",
       "min       0.001500     0.000600     0.001500     0.005800     0.006700   \n",
       "25%       0.013350     0.016450     0.018950     0.024375     0.038050   \n",
       "50%       0.022800     0.030800     0.034300     0.044050     0.062500   \n",
       "75%       0.035550     0.047950     0.057950     0.064500     0.100275   \n",
       "max       0.137100     0.233900     0.305900     0.426400     0.401000   \n",
       "\n",
       "       attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...   \n",
       "count   208.000000   208.000000   208.000000   208.000000    208.000000  ...  \\\n",
       "mean      0.104570     0.121747     0.134799     0.178003      0.208259  ...   \n",
       "std       0.059105     0.061788     0.085152     0.118387      0.134416  ...   \n",
       "min       0.010200     0.003300     0.005500     0.007500      0.011300  ...   \n",
       "25%       0.067025     0.080900     0.080425     0.097025      0.111275  ...   \n",
       "50%       0.092150     0.106950     0.112100     0.152250      0.182400  ...   \n",
       "75%       0.134125     0.154000     0.169600     0.233425      0.268700  ...   \n",
       "max       0.382300     0.372900     0.459000     0.682800      0.710600  ...   \n",
       "\n",
       "       attribute_51  attribute_52  attribute_53  attribute_54  attribute_55   \n",
       "count    208.000000    208.000000    208.000000    208.000000    208.000000  \\\n",
       "mean       0.016069      0.013420      0.010709      0.010941      0.009290   \n",
       "std        0.012008      0.009634      0.007060      0.007301      0.007088   \n",
       "min        0.000000      0.000800      0.000500      0.001000      0.000600   \n",
       "25%        0.008425      0.007275      0.005075      0.005375      0.004150   \n",
       "50%        0.013900      0.011400      0.009550      0.009300      0.007500   \n",
       "75%        0.020825      0.016725      0.014900      0.014500      0.012100   \n",
       "max        0.100400      0.070900      0.039000      0.035200      0.044700   \n",
       "\n",
       "       attribute_56  attribute_57  attribute_58  attribute_59  attribute_60  \n",
       "count    208.000000    208.000000    208.000000    208.000000    208.000000  \n",
       "mean       0.008222      0.007820      0.007949      0.007941      0.006507  \n",
       "std        0.005736      0.005785      0.006470      0.006181      0.005031  \n",
       "min        0.000400      0.000300      0.000300      0.000100      0.000600  \n",
       "25%        0.004400      0.003700      0.003600      0.003675      0.003100  \n",
       "50%        0.006850      0.005950      0.005800      0.006400      0.005300  \n",
       "75%        0.010575      0.010425      0.010350      0.010325      0.008525  \n",
       "max        0.039400      0.035500      0.044000      0.036400      0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr_raw = df_raw.loc[:, df_raw.columns != 'Class']\n",
    "df_cls = df_raw['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      208\n",
       "unique       2\n",
       "top       Mine\n",
       "freq       111\n",
       "Name: Class, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cls.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>attribute_6</th>\n",
       "      <th>attribute_7</th>\n",
       "      <th>attribute_8</th>\n",
       "      <th>attribute_9</th>\n",
       "      <th>attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>attribute_51</th>\n",
       "      <th>attribute_52</th>\n",
       "      <th>attribute_53</th>\n",
       "      <th>attribute_54</th>\n",
       "      <th>attribute_55</th>\n",
       "      <th>attribute_56</th>\n",
       "      <th>attribute_57</th>\n",
       "      <th>attribute_58</th>\n",
       "      <th>attribute_59</th>\n",
       "      <th>attribute_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   attribute_1  attribute_2  attribute_3  attribute_4  attribute_5   \n",
       "0       0.0200       0.0371       0.0428       0.0207       0.0954  \\\n",
       "1       0.0453       0.0523       0.0843       0.0689       0.1183   \n",
       "2       0.0262       0.0582       0.1099       0.1083       0.0974   \n",
       "3       0.0100       0.0171       0.0623       0.0205       0.0205   \n",
       "4       0.0762       0.0666       0.0481       0.0394       0.0590   \n",
       "\n",
       "   attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...   \n",
       "0       0.0986       0.1539       0.1601       0.3109        0.2111  ...  \\\n",
       "1       0.2583       0.2156       0.3481       0.3337        0.2872  ...   \n",
       "2       0.2280       0.2431       0.3771       0.5598        0.6194  ...   \n",
       "3       0.0368       0.1098       0.1276       0.0598        0.1264  ...   \n",
       "4       0.0649       0.1209       0.2467       0.3564        0.4459  ...   \n",
       "\n",
       "   attribute_51  attribute_52  attribute_53  attribute_54  attribute_55   \n",
       "0        0.0232        0.0027        0.0065        0.0159        0.0072  \\\n",
       "1        0.0125        0.0084        0.0089        0.0048        0.0094   \n",
       "2        0.0033        0.0232        0.0166        0.0095        0.0180   \n",
       "3        0.0241        0.0121        0.0036        0.0150        0.0085   \n",
       "4        0.0156        0.0031        0.0054        0.0105        0.0110   \n",
       "\n",
       "   attribute_56  attribute_57  attribute_58  attribute_59  attribute_60  \n",
       "0        0.0167        0.0180        0.0084        0.0090        0.0032  \n",
       "1        0.0191        0.0140        0.0049        0.0052        0.0044  \n",
       "2        0.0244        0.0316        0.0164        0.0095        0.0078  \n",
       "3        0.0073        0.0050        0.0044        0.0040        0.0117  \n",
       "4        0.0015        0.0072        0.0048        0.0107        0.0094  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cls.head()\n",
    "df_attr_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr = (df_attr_raw - df_attr_raw.min()) / (df_attr_raw.max() - df_attr_raw.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute_1</th>\n",
       "      <th>attribute_2</th>\n",
       "      <th>attribute_3</th>\n",
       "      <th>attribute_4</th>\n",
       "      <th>attribute_5</th>\n",
       "      <th>attribute_6</th>\n",
       "      <th>attribute_7</th>\n",
       "      <th>attribute_8</th>\n",
       "      <th>attribute_9</th>\n",
       "      <th>attribute_10</th>\n",
       "      <th>...</th>\n",
       "      <th>attribute_51</th>\n",
       "      <th>attribute_52</th>\n",
       "      <th>attribute_53</th>\n",
       "      <th>attribute_54</th>\n",
       "      <th>attribute_55</th>\n",
       "      <th>attribute_56</th>\n",
       "      <th>attribute_57</th>\n",
       "      <th>attribute_58</th>\n",
       "      <th>attribute_59</th>\n",
       "      <th>attribute_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.204011</td>\n",
       "      <td>0.162180</td>\n",
       "      <td>0.139068</td>\n",
       "      <td>0.114342</td>\n",
       "      <td>0.173732</td>\n",
       "      <td>0.253615</td>\n",
       "      <td>0.320472</td>\n",
       "      <td>0.285114</td>\n",
       "      <td>0.252485</td>\n",
       "      <td>0.281652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160047</td>\n",
       "      <td>0.180031</td>\n",
       "      <td>0.265172</td>\n",
       "      <td>0.290669</td>\n",
       "      <td>0.197061</td>\n",
       "      <td>0.200555</td>\n",
       "      <td>0.213642</td>\n",
       "      <td>0.175035</td>\n",
       "      <td>0.216015</td>\n",
       "      <td>0.136425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.169550</td>\n",
       "      <td>0.141277</td>\n",
       "      <td>0.126242</td>\n",
       "      <td>0.110623</td>\n",
       "      <td>0.140888</td>\n",
       "      <td>0.158843</td>\n",
       "      <td>0.167175</td>\n",
       "      <td>0.187767</td>\n",
       "      <td>0.175311</td>\n",
       "      <td>0.192215</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119607</td>\n",
       "      <td>0.137432</td>\n",
       "      <td>0.183385</td>\n",
       "      <td>0.213474</td>\n",
       "      <td>0.160717</td>\n",
       "      <td>0.147080</td>\n",
       "      <td>0.164361</td>\n",
       "      <td>0.148051</td>\n",
       "      <td>0.170286</td>\n",
       "      <td>0.116190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.087389</td>\n",
       "      <td>0.067938</td>\n",
       "      <td>0.057326</td>\n",
       "      <td>0.044163</td>\n",
       "      <td>0.079508</td>\n",
       "      <td>0.152714</td>\n",
       "      <td>0.209957</td>\n",
       "      <td>0.165215</td>\n",
       "      <td>0.132571</td>\n",
       "      <td>0.142964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083914</td>\n",
       "      <td>0.092368</td>\n",
       "      <td>0.118831</td>\n",
       "      <td>0.127924</td>\n",
       "      <td>0.080499</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.096591</td>\n",
       "      <td>0.075515</td>\n",
       "      <td>0.098485</td>\n",
       "      <td>0.057737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.157080</td>\n",
       "      <td>0.129447</td>\n",
       "      <td>0.107753</td>\n",
       "      <td>0.090942</td>\n",
       "      <td>0.141517</td>\n",
       "      <td>0.220236</td>\n",
       "      <td>0.280438</td>\n",
       "      <td>0.235061</td>\n",
       "      <td>0.214349</td>\n",
       "      <td>0.244673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138446</td>\n",
       "      <td>0.151213</td>\n",
       "      <td>0.235065</td>\n",
       "      <td>0.242690</td>\n",
       "      <td>0.156463</td>\n",
       "      <td>0.165385</td>\n",
       "      <td>0.160511</td>\n",
       "      <td>0.125858</td>\n",
       "      <td>0.173554</td>\n",
       "      <td>0.108545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.251106</td>\n",
       "      <td>0.202958</td>\n",
       "      <td>0.185447</td>\n",
       "      <td>0.139563</td>\n",
       "      <td>0.237319</td>\n",
       "      <td>0.333042</td>\n",
       "      <td>0.407738</td>\n",
       "      <td>0.361852</td>\n",
       "      <td>0.334555</td>\n",
       "      <td>0.368082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207420</td>\n",
       "      <td>0.227175</td>\n",
       "      <td>0.374026</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.260771</td>\n",
       "      <td>0.260897</td>\n",
       "      <td>0.287642</td>\n",
       "      <td>0.229977</td>\n",
       "      <td>0.281680</td>\n",
       "      <td>0.183025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       attribute_1  attribute_2  attribute_3  attribute_4  attribute_5   \n",
       "count   208.000000   208.000000   208.000000   208.000000   208.000000  \\\n",
       "mean      0.204011     0.162180     0.139068     0.114342     0.173732   \n",
       "std       0.169550     0.141277     0.126242     0.110623     0.140888   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.087389     0.067938     0.057326     0.044163     0.079508   \n",
       "50%       0.157080     0.129447     0.107753     0.090942     0.141517   \n",
       "75%       0.251106     0.202958     0.185447     0.139563     0.237319   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "       attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...   \n",
       "count   208.000000   208.000000   208.000000   208.000000    208.000000  ...  \\\n",
       "mean      0.253615     0.320472     0.285114     0.252485      0.281652  ...   \n",
       "std       0.158843     0.167175     0.187767     0.175311      0.192215  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000      0.000000  ...   \n",
       "25%       0.152714     0.209957     0.165215     0.132571      0.142964  ...   \n",
       "50%       0.220236     0.280438     0.235061     0.214349      0.244673  ...   \n",
       "75%       0.333042     0.407738     0.361852     0.334555      0.368082  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000      1.000000  ...   \n",
       "\n",
       "       attribute_51  attribute_52  attribute_53  attribute_54  attribute_55   \n",
       "count    208.000000    208.000000    208.000000    208.000000    208.000000  \\\n",
       "mean       0.160047      0.180031      0.265172      0.290669      0.197061   \n",
       "std        0.119607      0.137432      0.183385      0.213474      0.160717   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.083914      0.092368      0.118831      0.127924      0.080499   \n",
       "50%        0.138446      0.151213      0.235065      0.242690      0.156463   \n",
       "75%        0.207420      0.227175      0.374026      0.394737      0.260771   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       attribute_56  attribute_57  attribute_58  attribute_59  attribute_60  \n",
       "count    208.000000    208.000000    208.000000    208.000000    208.000000  \n",
       "mean       0.200555      0.213642      0.175035      0.216015      0.136425  \n",
       "std        0.147080      0.164361      0.148051      0.170286      0.116190  \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.102564      0.096591      0.075515      0.098485      0.057737  \n",
       "50%        0.165385      0.160511      0.125858      0.173554      0.108545  \n",
       "75%        0.260897      0.287642      0.229977      0.281680      0.183025  \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_attr.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mã hóa nhãn về dạng 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp(r):\n",
    "  if r == 'Rock':\n",
    "    return 1\n",
    "  return 0\n",
    "\n",
    "df_cls = df_raw['Class'].apply(lambda row : tmp(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cls.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thử chia dữ liệu train, test với random_state bất kì, tỉ lệ mặc định theo sklearn là 25% dữ liệu cho tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_attr, df_cls, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mặc định thì thư viện sklearn đã có hiệu chỉnh L2 vaf tự tìm tham số hiệu chỉnh tốt nhất. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linhnm/msc_source/social_stats/venv/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg_l2 = LogisticRegression(random_state=42, solver='saga')\n",
    "model_l2 = logreg_l2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8653846153846154, auc: 0.9378787878787879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "acc_l2 = model_l2.score(X_test, y_test)\n",
    "y_pred_prob_l2 = model_l2.predict_proba(X_test)[:,1]\n",
    "fpr_l2, tpr_l2, thresholds_l2 = roc_curve(y_test, y_pred_prob_l2)\n",
    "auc_roc_l2 = auc(fpr_l2, tpr_l2)\n",
    "\n",
    "print(f'acc: {acc_l2}, auc: {auc_roc_l2}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg_l1 = LogisticRegression(random_state=42, penalty='l1', solver='saga', max_iter=1000)\n",
    "model_l1 = logreg_l1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8461538461538461, auc: 0.9287878787878788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "acc_l1 = model_l1.score(X_test, y_test)\n",
    "y_pred_prob_l1 = model_l1.predict_proba(X_test)[:,1]\n",
    "fpr_l1, tpr_l1, thresholds_l1 = roc_curve(y_test, y_pred_prob_l1)\n",
    "auc_roc_l1 = auc(fpr_l1, tpr_l1)\n",
    "\n",
    "print(f'acc: {acc_l1}, auc: {auc_roc_l1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_els = LogisticRegression(random_state=42, penalty='elasticnet', l1_ratio=0.5, solver='saga', max_iter=1000)\n",
    "model_els = logreg_els.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8653846153846154, auc: 0.9348484848484848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "acc_els = model_els.score(X_test, y_test)\n",
    "y_pred_prob_els = model_els.predict_proba(X_test)[:,1]\n",
    "fpr_els, tpr_els, thresholds_els = roc_curve(y_test, y_pred_prob_els)\n",
    "auc_roc_els = auc(fpr_els, tpr_els)\n",
    "\n",
    "print(f'acc: {acc_els}, auc: {auc_roc_els}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chúng ta đi tìm mô hình tốt nhất bằng cách chia tập train và test theo nhiều cách khác nhau. Có thể sử dụng k-fold nhưng nhìn chung với mỗi cách chia tập train, test, ta sẽ có một mô hình khác nhau và từ đó tìm ra mô hình tốt nhất hay là mô hình có chỉ số AUC của ROC curve là cao nhất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_random_state(df_features, df_labels, N, logreg):\n",
    "  X_train = list()\n",
    "  X_test = list()\n",
    "  y_train = list()\n",
    "  y_test = list()\n",
    "  model = list()\n",
    "  auc_model = list()\n",
    "  for i in range(N):\n",
    "    _X_train, _X_test, _y_train, _y_test = train_test_split(df_features, df_labels, random_state=i)\n",
    "    X_train.append(_X_train)\n",
    "    X_test.append(_X_test)\n",
    "    y_train.append(_y_train)\n",
    "    y_test.append(_y_test)\n",
    "    \n",
    "    logreg.random_state = i\n",
    "    _model = logreg.fit(_X_train, _y_train)\n",
    "    # tmp = _model.get_params()\n",
    "    # print(tmp)\n",
    "    model.append(_model)\n",
    "    _y_pred_prob = _model.predict_proba(_X_test)[:,1]\n",
    "    \n",
    "    auc_model.append(roc_auc_score(_y_test, _y_pred_prob))\n",
    "    \n",
    "  return X_train, X_test, y_train, y_test, model, auc_model\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thử với 1000 cách chia tập train, test với tỉ lệ mặc định 0.25 cho tập test, lấy ra mô hình có AUC cao nhất. Giá trị tìm được là 0.987, tốt hơn so với mô hình trước đó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_l1 = LogisticRegression(random_state=42, penalty='l1', solver='saga', max_iter=1000)\n",
    "logreg_l2 = LogisticRegression(random_state=42, penalty='l2', solver='saga', max_iter=1000)\n",
    "logreg_els = LogisticRegression(random_state=42, penalty='elasticnet', l1_ratio=0.5, solver='saga', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, model, auc_model = scan_random_state(df_attr, df_cls, 1000, logreg_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best random state: 889 with auc: 0.9792592592592593\n"
     ]
    }
   ],
   "source": [
    "auc_model\n",
    "\n",
    "max_auc = max(auc_model)\n",
    "best_random_state = auc_model.index(max_auc)\n",
    "\n",
    "print(f'best random state: {best_random_state} with auc: {max_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, model, auc_model = scan_random_state(df_attr, df_cls, 1000, logreg_els)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best random state: 889 with auc: 0.9807407407407407\n"
     ]
    }
   ],
   "source": [
    "auc_model\n",
    "\n",
    "max_auc = max(auc_model)\n",
    "best_random_state = auc_model.index(max_auc)\n",
    "\n",
    "print(f'best random state: {best_random_state} with auc: {max_auc}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta có thể lặp lại các tính toán trên với việc phân tích thành phần chính (PCA) cho tập dữ liệu sonar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trước hết ta chọn ngẫu nhiên số chiều dữ liệu, ở đây tôi chọn là 30 trên 60 và thử tính toán như trên."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=30)\n",
    "df_attr_pca = df_attr\n",
    "df_attr_pca = pca.fit_transform(df_attr_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attr_pca.shape\n",
    "df_attr_pca = pd.DataFrame(df_attr_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 30 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 48.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_attr_pca.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_attr_pca, df_cls, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thử scan với 1000 random_state khác nhau ta được auc tốt nhất là 0.993, tốt hơn khi không dùng PCA.\n",
    "\n",
    "Accuracy của mô hình là 0.903 không khác so với việc không dùng PCA. Tuy nhiên mô hình trở nên đơn giản hơn nhiều và quá trình train hay scan random_state cũng nhanh hơn nhiều do số lượng features chỉ con một nửa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, model, auc_model = scan_random_state(df_attr_pca, df_cls, 1000, logreg_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best random state: 889 with auc: 0.9718518518518519\n",
      "best random state: 889 with accuracy: 0.9423076923076923\n"
     ]
    }
   ],
   "source": [
    "max_auc = max(auc_model)\n",
    "best_random_state = auc_model.index(max_auc)\n",
    "\n",
    "print(f'best random state: {best_random_state} with auc: {max_auc}')\n",
    "\n",
    "score = model[best_random_state].score(X_test[best_random_state], y_test[best_random_state])\n",
    "print(f'best random state: {best_random_state} with accuracy: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_num_feature(min_num_feature, max_num_feature, N_rand_state, logreg):\n",
    "  X_train_dict = dict()\n",
    "  X_test_dict = dict()\n",
    "  y_train_dict = dict()\n",
    "  y_test_dict = dict()\n",
    "  model_dict = dict()\n",
    "  auc_model_dict = dict()\n",
    "  best_random_state_dict = dict()\n",
    "  \n",
    "  for i in range(min_num_feature, max_num_feature):\n",
    "    pca = PCA(n_components=i)\n",
    "    df_attr_pca = df_attr\n",
    "    df_attr_pca = pca.fit_transform(df_attr_pca)\n",
    "    df_attr_pca = pd.DataFrame(df_attr_pca)\n",
    "    X_train, X_test, y_train, y_test, model, auc_model = scan_random_state(df_attr_pca, df_cls, N_rand_state, logreg)\n",
    "    \n",
    "    max_auc = max(auc_model)\n",
    "    best_random_state = auc_model.index(max_auc)\n",
    "    \n",
    "    X_train_dict[i] = X_train[best_random_state]\n",
    "    X_test_dict[i] = X_test[best_random_state]\n",
    "    y_train_dict[i] = y_train[best_random_state]\n",
    "    y_test_dict[i] = y_test[best_random_state]\n",
    "    model_dict[i] = model[best_random_state]\n",
    "    auc_model_dict[i] = auc_model[best_random_state]\n",
    "    best_random_state_dict[i] = best_random_state\n",
    "\n",
    "    print(f'number of features: {i}, best random state: {best_random_state} with auc: {max_auc}')\n",
    "\n",
    "    score = model[best_random_state].score(X_test[best_random_state], y_test[best_random_state])\n",
    "    print(f'number of features: {i}, best random state: {best_random_state} with accuracy: {score}')\n",
    "    \n",
    "  return X_train_dict, X_test_dict, y_train_dict, y_test_dict, model_dict, auc_model_dict, best_random_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 1, best random state: 541 with auc: 0.794074074074074\n",
      "number of features: 1, best random state: 541 with accuracy: 0.5192307692307693\n",
      "number of features: 2, best random state: 604 with auc: 0.8500749625187407\n",
      "number of features: 2, best random state: 604 with accuracy: 0.5961538461538461\n",
      "number of features: 3, best random state: 385 with auc: 0.9712918660287082\n",
      "number of features: 3, best random state: 385 with accuracy: 0.8461538461538461\n",
      "number of features: 4, best random state: 285 with auc: 0.9614814814814815\n",
      "number of features: 4, best random state: 285 with accuracy: 0.8846153846153846\n",
      "number of features: 5, best random state: 889 with auc: 0.9422222222222222\n",
      "number of features: 5, best random state: 889 with accuracy: 0.8653846153846154\n",
      "number of features: 6, best random state: 889 with auc: 0.9540740740740741\n",
      "number of features: 6, best random state: 889 with accuracy: 0.8846153846153846\n",
      "number of features: 7, best random state: 889 with auc: 0.9762962962962963\n",
      "number of features: 7, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 8, best random state: 889 with auc: 0.9718518518518519\n",
      "number of features: 8, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 9, best random state: 889 with auc: 0.9733333333333333\n",
      "number of features: 9, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 10, best random state: 889 with auc: 0.9703703703703703\n",
      "number of features: 10, best random state: 889 with accuracy: 0.9423076923076923\n",
      "number of features: 11, best random state: 889 with auc: 0.9703703703703703\n",
      "number of features: 11, best random state: 889 with accuracy: 0.9423076923076923\n",
      "number of features: 12, best random state: 889 with auc: 0.9733333333333334\n",
      "number of features: 12, best random state: 889 with accuracy: 0.9423076923076923\n",
      "number of features: 13, best random state: 889 with auc: 0.9837037037037037\n",
      "number of features: 13, best random state: 889 with accuracy: 0.9423076923076923\n",
      "number of features: 14, best random state: 889 with auc: 0.9837037037037037\n",
      "number of features: 14, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 15, best random state: 889 with auc: 0.991111111111111\n",
      "number of features: 15, best random state: 889 with accuracy: 0.9423076923076923\n",
      "number of features: 16, best random state: 889 with auc: 0.991111111111111\n",
      "number of features: 16, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 17, best random state: 889 with auc: 0.9896296296296296\n",
      "number of features: 17, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 18, best random state: 889 with auc: 0.991111111111111\n",
      "number of features: 18, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 19, best random state: 889 with auc: 0.9881481481481481\n",
      "number of features: 19, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 20, best random state: 889 with auc: 0.9866666666666666\n",
      "number of features: 20, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 21, best random state: 889 with auc: 0.9896296296296296\n",
      "number of features: 21, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 22, best random state: 889 with auc: 0.9940740740740741\n",
      "number of features: 22, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 23, best random state: 889 with auc: 0.9940740740740741\n",
      "number of features: 23, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 24, best random state: 889 with auc: 0.9940740740740741\n",
      "number of features: 24, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 25, best random state: 889 with auc: 0.9911111111111112\n",
      "number of features: 25, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 26, best random state: 889 with auc: 0.9940740740740741\n",
      "number of features: 26, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 27, best random state: 889 with auc: 0.9925925925925927\n",
      "number of features: 27, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 28, best random state: 889 with auc: 0.9925925925925926\n",
      "number of features: 28, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 29, best random state: 889 with auc: 0.9925925925925926\n",
      "number of features: 29, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 30, best random state: 889 with auc: 0.9925925925925926\n",
      "number of features: 30, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 31, best random state: 889 with auc: 0.9925925925925926\n",
      "number of features: 31, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 32, best random state: 889 with auc: 0.991111111111111\n",
      "number of features: 32, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 33, best random state: 889 with auc: 0.991111111111111\n",
      "number of features: 33, best random state: 889 with accuracy: 0.9423076923076923\n",
      "number of features: 34, best random state: 889 with auc: 0.991111111111111\n",
      "number of features: 34, best random state: 889 with accuracy: 0.9423076923076923\n",
      "number of features: 35, best random state: 889 with auc: 0.9896296296296296\n",
      "number of features: 35, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 36, best random state: 889 with auc: 0.9881481481481481\n",
      "number of features: 36, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 37, best random state: 889 with auc: 0.9881481481481481\n",
      "number of features: 37, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 38, best random state: 889 with auc: 0.9881481481481481\n",
      "number of features: 38, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 39, best random state: 889 with auc: 0.9881481481481481\n",
      "number of features: 39, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 40, best random state: 889 with auc: 0.9866666666666666\n",
      "number of features: 40, best random state: 889 with accuracy: 0.9230769230769231\n",
      "number of features: 41, best random state: 889 with auc: 0.9881481481481481\n",
      "number of features: 41, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 42, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 42, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 43, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 43, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 44, best random state: 889 with auc: 0.9851851851851852\n",
      "number of features: 44, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 45, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 45, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 46, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 46, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 47, best random state: 889 with auc: 0.9881481481481481\n",
      "number of features: 47, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 48, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 48, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 49, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 49, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 50, best random state: 889 with auc: 0.9881481481481482\n",
      "number of features: 50, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 51, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 51, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 52, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 52, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 53, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 53, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 54, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 54, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 55, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 55, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 56, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 56, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 57, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 57, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 58, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 58, best random state: 889 with accuracy: 0.9038461538461539\n",
      "number of features: 59, best random state: 889 with auc: 0.9866666666666667\n",
      "number of features: 59, best random state: 889 with accuracy: 0.9038461538461539\n"
     ]
    }
   ],
   "source": [
    "X_train_dict, X_test_dict, y_train_dict, y_test_dict, model_dict, auc_model_dict, best_random_state_dict = scan_num_feature(1, 60, 1000, logreg_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features with best auc: [22, 23, 24, 26]\n",
      "best auc: 0.9940740740740741\n",
      "accuracy: 0.9230769230769231\n",
      "best random state: 889\n"
     ]
    }
   ],
   "source": [
    "best_num_feature = [key for key, value in auc_model_dict.items() if value == max(auc_model_dict.values())]\n",
    "\n",
    "j = best_num_feature[0]\n",
    "\n",
    "print(f'number of features with best auc: {best_num_feature}')\n",
    "print(f'best auc: {auc_model_dict[j]}')\n",
    "print(f'accuracy: {model_dict[j].score(X_test_dict[j], y_test_dict[j])}')\n",
    "print(f'best random state: {best_random_state_dict[j]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ta thấy rằng thực hiện phân tích thành phần chính với 22 feature cho ra kết quả tốt nhất với auc = 0.994, tốt hơn với việc dùng cả 60 features với auc = 0.925. Như vậy mô hình tốt logistic regression nhất cho bài toán này PCA với 22 features, random_state = 899, accuracy = 0.923. \n",
    "\n",
    "Một điều thú vị là khi phân tích pca ta thấy rằng chỉ với 3 chiều chính, ta đã có auc = 0.971 và accuracy = 0.846 cao hơn khi dùng cả 60 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../model/pca_data_best_model.sav'\n",
    "pickle.dump(model_dict[j], open(file_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_dict[j].predict(X_test_dict[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91        25\n",
      "           1       0.87      1.00      0.93        27\n",
      "\n",
      "    accuracy                           0.92        52\n",
      "   macro avg       0.94      0.92      0.92        52\n",
      "weighted avg       0.93      0.92      0.92        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# confusion matrix\n",
    "print(classification_report(y_test_dict[j], y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
